# Logger parameters
logger:
  workspace: harshrangwala # workspace name
  project: ssl_roughness_end2end # project name
  experiment_name: dtask3-end2end # name of the experiment
  tags: "Roughness DT"
  resume: False # (boolean) whether to resume training or not
  online: True # (boolean) whether to store logs online or not
  experiment_key: "mqJkyVqrHSBGEt2wkbMP7wWQP" # can be retrieved from logger dashboard, available if only resuming
  api_key: "mqJkyVqrHSBGEt2wkbMP7wWQP"
  offline_directory: ./logs # where to store log data
  disabled: False # disable the comet ml
  upload_model: False # upload the model to CometML
  log_env_details: False # log virtual environment details
  auto_histogram_weight_logging: True # allows you to enable/disable histogram logging for biases and weights
  auto_histogram_gradient_logging: True # allows you to enable/disable automatic histogram logging of gradients
  auto_histogram_activation_logging: True # allows you to enable/disable automatic histogram logging of activations

# Training parameters
train_params:
  experiment_name: dt_roughness_end2end  # Will be auto-generated in the code
  epochs: 100
  device: cuda:0
  grad_clipping: 1.0
  save_every: 50  # Save checkpoint every N epochs
  optimizer: "adamw"  # Options: adamw, rmsprop, sgd
  resume_dtr: False  
  loss: mse
  early_stop_patience: 15
  early_stop_delta: 0.0005

# Directory settings
directory:
  model_name: null  # Will be auto-generated in the code
  save: "/mnt/sbackup/Server_3/harshr/home/NV_cahsor/CAHSOR-master/TRON/checkpoint/tron/decoder_rg_thermal_lidar_elev_ckpts"
  pretrained_path: "/mnt/sbackup/Server_3/harshr/home/NV_cahsor/CAHSOR-master/TRON/checkpoint/tron/ssl-ptr-thermal_lidar_imu_elev-2048-04-16-20-52/ssl-ptr-thermal_lidar_imu_elev-2048-04-18-15-08/ssl-ptr-thermal_lidar_imu_elev-2048-04-18-15-08_500.pth" 
  resume_roughness_model_path: null

# Dataset parameters
dataset:
  root: /mnt/sbackup/Server_3/harshr/m2p2_data # where data resides
  seed: 42 # random seed for random transformations
  resize:
    - 256
    - 256

# DataLoader parameters
dataloader:
  batch_size: 128
  shuffle: true
  num_workers: 4
  pin_memory: true
  drop_last: true

model:
  rep_size: 2048 
  num_layers_enc: 50
  hidden_dims: [512, 128, 32]

# Weight initialization parameters
init_weights:
  method: "normal"

# Optimizer configurations
rg_dt_adamw:
  lr: 2e-4
  eps: 1e-8
  betas: [0.9, 0.999]
  weight_decay: 3e-5 
  amsgrad: True

rmsprop:
  lr: 1.0e-4
  weight_decay: 1.0e-4
  momentum: 0.9

sgd:
  lr: 1.0e-3
  weight_decay: 1.0e-4
  momentum: 0.9

  # Scheduler parameters
scheduler:
  final_lr: 1.0e-6

